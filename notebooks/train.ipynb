{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1555d26d",
   "metadata": {},
   "source": [
    "# üöÄ HyperSloth Demo Training Notebook\n",
    "\n",
    "This notebook demonstrates how to fine-tune large language models using HyperSloth's multi-GPU capabilities. It's equivalent to running:\n",
    "\n",
    "```bash\n",
    "hypersloth-train examples/example_sharegpt_lora_2gpus.py\n",
    "```\n",
    "\n",
    "## What This Demo Does\n",
    "\n",
    "- **Multi-GPU Training**: Uses 2 GPUs with NCCL synchronization\n",
    "- **Adaptive Batching**: Optimizes sequence sorting and padding\n",
    "- **LoRA Fine-tuning**: Efficient parameter updates with Low-Rank Adaptation\n",
    "- **Response-only Loss**: Calculates loss only on assistant responses\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. HyperSloth installed: `pip install git+https://github.com/anhvth/HyperSloth.git`\n",
    "2. At least 2 GPUs available (adjust `gpus=[0, 1]` if needed)\n",
    "3. Sufficient VRAM (reduce batch size if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a817bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HyperSloth configuration classes\n",
    "from HyperSloth.hypersloth_config import *\n",
    "from HyperSloth.scripts.hp_trainer import run_multiprocess_training, setup_envs\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f'üî• CUDA Available: {torch.cuda.is_available()}')\n",
    "print(f'üî• GPU Count: {torch.cuda.device_count()}')\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f'   GPU {i}: {torch.cuda.get_device_name(i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606c272",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration Setup\n",
    "\n",
    "HyperSloth uses Pydantic models for type-safe configuration. We'll set up:\n",
    "\n",
    "1. **Data Configuration**: Dataset and tokenization settings\n",
    "2. **Training Configuration**: GPU allocation and loss calculation\n",
    "3. **Model Configuration**: Base model and LoRA parameters\n",
    "4. **Training Arguments**: Learning rate, batch size, and optimization settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f33c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperSloth.hypersloth_config import *\n",
    "from HyperSloth.scripts.hp_trainer import run_multiprocess_training, setup_envs\n",
    "\n",
    "# Main configuration using Pydantic models\n",
    "hyper_config_model = HyperConfig(\n",
    "    data=HFDatasetConfig(\n",
    "        dataset_name=\"llamafactory/OpenThoughts-114k\",\n",
    "        split=\"train\",\n",
    "        tokenizer_name=\"Qwen/Qwen3-8B\",  # does not matter same family qwen3\n",
    "        num_samples=1000,\n",
    "        instruction_part=\"<|im_start|>user\\n\",\n",
    "        response_part=\"<|im_start|>assistant\\n\",\n",
    "        chat_template=\"chatml\",\n",
    "    ),\n",
    "    training=TrainingConfig(\n",
    "        gpus=[0, 1],\n",
    "        loss_type=\"response_only\",\n",
    "    ),\n",
    "    fast_model_args=FastModelArgs(\n",
    "        model_name=\"unsloth/Qwen3-0.6b-bnb-4bit\",\n",
    "        max_seq_length=32_000,\n",
    "        load_in_4bit=True,\n",
    "    ),\n",
    "    lora_args=LoraArgs(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "        ],\n",
    "        lora_dropout=0,\n",
    "        bias=\"none\",\n",
    "        use_rslora=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Training arguments using Pydantic model\n",
    "training_config_model = TrainingArgsConfig(\n",
    "    output_dir=\"outputs/qwen3-8b-openthought-2gpus/\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    logging_steps=3,\n",
    "    num_train_epochs=3,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=5,\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_8bit\",\n",
    "    seed=3407,\n",
    "    report_to=\"none\",  # tensorboard or wawndb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d9548",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training Arguments\n",
    "\n",
    "Configure the training hyperparameters for optimal performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b45e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global batch size: 16\n",
      "[MP] Running on 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m03:05:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mhp_trainer.py:44\u001b[0m | \u001b[1müîß GPU 1 (Rank 1/1) | Model: unsloth/Qwen3-0.6b-bnb-4bit\u001b[0m\n",
      "\u001b[32m03:05:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mhp_trainer.py:50\u001b[0m | \u001b[1mTraining on GPU 1 with output_dir outputs/qwen3-8b-openthought-2gpus/\u001b[0m\n",
      "\u001b[32m03:05:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mhp_trainer.py:53\u001b[0m | \u001b[1müöÄ Starting total training timer\u001b[0m\n",
      "\u001b[32m03:05:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mhp_trainer.py:44\u001b[0m | \u001b[1müîß GPU 0 (Rank 0/1) | Model: unsloth/Qwen3-0.6b-bnb-4bit\u001b[0m\n",
      "\u001b[32m03:05:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mhp_trainer.py:50\u001b[0m | \u001b[1mTraining on GPU 0 with output_dir outputs/qwen3-8b-openthought-2gpus/\u001b[0m\n",
      "\u001b[32m03:05:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mhp_trainer.py:53\u001b[0m | \u001b[1müöÄ Starting total training timer\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.5.9: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.189 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.5.9: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.189 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m03:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  model_loading: 15.26s\u001b[0m\n",
      "\u001b[32m03:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mnccl_grad_sync.py:127\u001b[0m | \u001b[1m[GPU=1] NCCL env: RANK=1, WORLD_SIZE=2, MASTER_ADDR=127.0.0.1, MASTER_PORT=29500\u001b[0m\n",
      "\u001b[32m03:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mnccl_grad_sync.py:146\u001b[0m | \u001b[1m[GPU=1] Setting current CUDA device to:0\u001b[0m\n",
      "\u001b[32m03:06:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  model_loading: 14.46s\u001b[0m\n",
      "\u001b[32m03:06:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mnccl_grad_sync.py:127\u001b[0m | \u001b[1m[GPU=0] NCCL env: RANK=0, WORLD_SIZE=2, MASTER_ADDR=127.0.0.1, MASTER_PORT=29500\u001b[0m\n",
      "\u001b[32m03:06:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mnccl_grad_sync.py:146\u001b[0m | \u001b[1m[GPU=0] Setting current CUDA device to:0\u001b[0m\n",
      "\u001b[32m03:06:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mnccl_grad_sync.py:160\u001b[0m | \u001b[1m[GPU=1] NCCL setup complete: rank=1, world_size=2, attempt=1\u001b[0m\n",
      "\u001b[32m03:06:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minit_modules.py:49\u001b[0m | \u001b[1mModel loaded on device cuda:0, tokenizer: Qwen2TokenizerFast\u001b[0m\n",
      "\u001b[32m03:06:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mnccl_grad_sync.py:160\u001b[0m | \u001b[1m[GPU=0] NCCL setup complete: rank=0, world_size=2, attempt=1\u001b[0m\n",
      "\u001b[32m03:06:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minit_modules.py:49\u001b[0m | \u001b[1mModel loaded on device cuda:0, tokenizer: Qwen2TokenizerFast\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  model_init: 18.04s\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mdataset_utils.py:283\u001b[0m | \u001b[1mLoading dataset... and tokenize\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mdataset_utils.py:299\u001b[0m | \u001b[1mFinal dataset loaded with 1000 samples (cache_id: abb36c5638db...)\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minit_modules.py:131\u001b[0m | \u001b[1mCreating final SFTTrainer with prepared dataset...\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  model_init: 19.57s\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mdataset_utils.py:283\u001b[0m | \u001b[1mLoading dataset... and tokenize\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mdataset_utils.py:299\u001b[0m | \u001b[1mFinal dataset loaded with 1000 samples (cache_id: abb36c5638db...)\u001b[0m\n",
      "\u001b[32m03:06:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minit_modules.py:131\u001b[0m | \u001b[1mCreating final SFTTrainer with prepared dataset...\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minit_modules.py:146\u001b[0m | \u001b[1mReplacing DataCollatorForLanguageModeling with DataCollatorForSeq2Seq for better sequence handling\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minit_modules.py:154\u001b[0m | \u001b[1mTrainer setup completed successfully\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minner_training_loop.py:256\u001b[0m | \u001b[1mHyperSloth ultra-minimal patches applied successfully (rank 0/2)\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mpatch_sampler.py:70\u001b[0m | \u001b[1müîß Patching Trainer to use RandomSamplerSeededByEpoch\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mpatch_sampler.py:86\u001b[0m | \u001b[1mAdd callback ShuffleData to Trainer UnslothSFTTrainer\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  total_setup: 48.71s\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  model_and_training_setup: 48.76s\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mnccl_grad_sync.py:49\u001b[0m | \u001b[1m[GPU=0] NCCLGradSyncCallback initialized for rank 0/2\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mhp_trainer.py:72\u001b[0m | \u001b[1mUsing gradient sync callback for GPU 0\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minit_modules.py:146\u001b[0m | \u001b[1mReplacing DataCollatorForLanguageModeling with DataCollatorForSeq2Seq for better sequence handling\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minit_modules.py:154\u001b[0m | \u001b[1mTrainer setup completed successfully\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minner_training_loop.py:256\u001b[0m | \u001b[1mHyperSloth ultra-minimal patches applied successfully (rank 1/2)\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mpatch_sampler.py:70\u001b[0m | \u001b[1müîß Patching Trainer to use RandomSamplerSeededByEpoch\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mpatch_sampler.py:86\u001b[0m | \u001b[1mAdd callback ShuffleData to Trainer UnslothSFTTrainer\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  total_setup: 49.03s\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mlogging_config.py:407\u001b[0m | \u001b[1m‚è±Ô∏è  model_and_training_setup: 49.07s\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mnccl_grad_sync.py:49\u001b[0m | \u001b[1m[GPU=1] NCCLGradSyncCallback initialized for rank 1/2\u001b[0m\n",
      "\u001b[32m03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mhp_trainer.py:72\u001b[0m | \u001b[1mUsing gradient sync callback for GPU 1\u001b[0m\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 3 | Total steps = 189\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 5,046,272/6,000,000,000 (0.08% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 3 | Total steps = 189\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 5,046,272/6,000,000,000 (0.08% trained)\n",
      "\u001b[32m03:06:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mpatch_sampler.py:21\u001b[0m | \u001b[1müîÑ Starting epoch 1\u001b[0m\n",
      "\u001b[32m03:06:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mpatch_sampler.py:52\u001b[0m | \u001b[1müé≤ Sampler epoch 0: emitting 1000 indices\n",
      "First ids: [776, 507, 895, 922, 33, 483, 85, 750, 354, 523]\n",
      "Last ids: [104, 754, 142, 228, 250, 281, 759, 25, 114, 654]\u001b[0m\n",
      "\u001b[32m03:06:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36mpatch_sampler.py:52\u001b[0m | \u001b[1müé≤ Sampler epoch 0: emitting 1000 indices\n",
      "First ids: [776, 507, 895, 922, 33, 483, 85, 750, 354, 523]\n",
      "Last ids: [104, 754, 142, 228, 250, 281, 759, 25, 114, 654]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE #1 ===\n",
      "\u001b[92m<|im_start|>system\n",
      "You are an assistant that thoroughly explores questions through a systematic long thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarization, exploration, reassessment, reflection, backtracing, and iteration to develop a well-considered thinking process. Detail your reasoning process using the specified format: <think>thought with steps separated by '\n",
      "\n",
      "'</think> Each step should include detailed considerations such as analyzing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. Based on various attempts, explorations, and reflections from the thoughts, you should systematically present the final solution that you deem correct. The solution should remain a logical, accurate, concise expression style and detail necessary steps needed to reach the conclusion. Now, try to solve the following question through the above guidelines.<|im_end|>\n",
      "<|im_start|>user\n",
      "A ski lift carries a skier at a rate of 12 kilometers per hour. How many kilometers does the ski lift carry the skier in 10 minutes?\n",
      "(A) 120\n",
      "(B) 1.2\n",
      "(C) 2\n",
      "(D) 2.4\n",
      "(E) 1.67<|im_end|>\n",
      "<|im_start|>assistant\n",
      "... (truncated)\u001b[0m\u001b[93m<think>\n",
      "Okay, so I need to figure out how many kilometers the ski lift carries the skier in 10 minutes. The problem says the ski lift's rate is 12 kilometers per hour. Hmm, right. Let me start by understanding what the question is asking.\n",
      "\n",
      "First, speed is given in kilometers per hour, but the time we're looking at is in minutes. I remember that when dealing with speed, time, and distance, the formula is distance equals speed multiplied by time. But here, the units don't match‚Äîspeed is per hour, and time is in minutes. So, I need to convert either the time to hours or the speed to kilometers per minute. Maybe converting minutes to hours would be easier here.\n",
      "\n",
      "Wait, 10 minutes is a fraction of an hour. Since there are 60 minutes in an hour, 10 minutes would be 10/60 hours. Let me write that down. 10 divided by 60 is... let's see, 10/60 simplifies to 1/6, which is approximately 0.1667 hours. Yeah, that makes sense because 10 minutes is a sixth of an hour.\n",
      "\n",
      "So, if the ski lift is moving at 12 km/h, then in one hour, it would cover 12 km. But we only need a tenth of an hour? Wait, no‚Äî10 minutes is 1/6 of an hour, not a tenth. Wait, 10 divided by 60 is indeed 1/6. Right. So, maybe I confused that with 10 minutes being 0.1 hours, but no, 0.1 hours is 6 minutes. So 10 minutes is more than that. So 10/60 = 1/6 ‚âà 0.1667 hours. Got it.\n",
      "\n",
      "So, the distance would be speed multiplied by time. So that's 12 km/h multiplied by 1/6 hour. Let's compute that. 12 multiplied by 1/6 is 12/6, which is 2. So, 2 kilometers. Wait, but hold on. Let me check that again. 12 divided by 6 is 2, yes. So, 12 km/h times 1/6 hour equals 2 km. That seems straightforward.\n",
      "\n",
      "But let me make sure I didn't make a mistake in converting minutes to hours. Let's verify. 60 minutes = 1 hour. Therefore, 1 minute = 1/60 hour. So, 10 minutes = 10 * (1/60) = 10/60 = 1/6 hour. That's correct. So, 12 * (1/6) = 2. So, the answer should be 2 km, which is option C.\n",
      "\n",
      "Wait, but let me see the options again. The options are (A) 120, (B) 1.2, (C) 2, (D) 2.4, (E) 1.67. So, 2 is option C. Hmm. But another way to think about it is maybe the speed is 12 km per hour, so per minute it would be 12 divided by 60, which is 0.2 km per minute. Then, 0.2 km/min times 10 minutes equals 2 km. Yeah, that also gives the same answer. So either way, converting time to hours or converting speed to km per minute, the result is 2 km. Therefore, the correct answer is C.\n",
      "\n",
      "But wait, why is there an option E, 1.67? Maybe someone could miscalculate. Let me check if I did something wrong. For instance, if someone thought 10 minutes is 0.1 hours, then 12 * 0.1 would be 1.2, which is option B. But that's incorrect because 10 minutes is not 0.1 hours. 0.1 hours is 6 minutes. So, perhaps a common mistake is to divide by 100 instead of 60. But in this case, the correct conversion is 10/60, which is 1/6, so 12 * (1/6) is 2. So, answer C is correct. Therefore, the answer is C, 2.\n",
      "</think>\n",
      "\n",
      "To determine how many kilometers the ski lift carries the skier in 10 minutes, we use the formula:\n",
      "\n",
      "\\[\n",
      "\\text{Distance} = \\text{Speed} \\times \\text{Time}\n",
      "\\]\n",
      "\n",
      "**Given:**\n",
      "- Speed = 12 km/h  \n",
      "- Time = 10 minutes  \n",
      "\n",
      "**Step 1: Convert time to hours**  \n",
      "Since 1 hour = 60 minutes,  \n",
      "\\[\n",
      "10\\ \\text{minutes} = \\frac{10}{60}\\ \\text{hours} = \\frac{1}{6}\\ \\text{hours} \\approx 0.1667\\ \\text{hours}.\n",
      "\\]\n",
      "\n",
      "**Step 2: Calculate distance**  \n",
      "\\[\n",
      "\\text{Distance} = 12\\ \\text{km/h} \\times \\frac{1}{6}\\ \\text{hours} = 2\\ \\text{km}.\n",
      "\\]\n",
      "\n",
      "**Verification via alternative method:**  \n",
      "Convert speed to km/minute:  \n",
      "\\[\n",
      "12\\ \\text{km/h} = \\frac{12}{60}\\ \\text{km/min} = 0.2\\ \\text{km/min}.\n",
      "\\]\n",
      "\\[\n",
      "\\text{Distance} = 0.2\\ \\text{km/min} \\times 10\\ \\text{min} = 2\\ \\text{km}.\n",
      "\\]\n",
      "\n",
      "**Conclusion:**  \n",
      "The ski lift carries the skier **2 kilometers** in 10 minutes.  \n",
      "\n",
      "**Answer:** (C) 2<|im_end|>\n",
      "... (truncated)\u001b[0m\u001b[92m... padding 2044 tokens\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More training debug examples written to .log/dataloader_examples.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m03:06:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mpatch_sampler.py:28\u001b[0m | \u001b[1müìã Dataloader examples logged to .log/dataloader_examples.html\u001b[0m\n",
      "\u001b[32m03:06:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mpatch_sampler.py:52\u001b[0m | \u001b[1müé≤ Sampler epoch 0: emitting 1000 indices\n",
      "First ids: [776, 507, 895, 922, 33, 483, 85, 750, 354, 523]\n",
      "Last ids: [104, 754, 142, 228, 250, 281, 759, 25, 114, 654]\u001b[0m\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21/189 02:09 < 19:07, 0.15 it/s, Epoch 0.32/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.736300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.703300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21/189 02:09 < 19:07, 0.15 it/s, Epoch 0.32/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m03:07:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minner_training_loop.py:100\u001b[0m | \u001b[1m\n",
      "üöÄ HyperSloth Token Efficiency Report (Rank 0)\n",
      "+---------------------+----------------+-----------------------+\n",
      "| Stage               |   Total Tokens |   Token Utilization % |\n",
      "+=====================+================+=======================+\n",
      "| Before Optimization |      1,283,882 |                67.39% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "| After Optimization  |        865,203 |               100.00% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "\u001b[0m\n",
      "\u001b[32m03:07:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minner_training_loop.py:100\u001b[0m | \u001b[1m\n",
      "üöÄ HyperSloth Token Efficiency Report (Rank 1)\n",
      "+---------------------+----------------+-----------------------+\n",
      "| Stage               |   Total Tokens |   Token Utilization % |\n",
      "+=====================+================+=======================+\n",
      "| Before Optimization |      1,283,882 |                67.39% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "| After Optimization  |        865,203 |               100.00% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "\u001b[0m\n",
      "\u001b[32m03:08:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36minner_training_loop.py:100\u001b[0m | \u001b[1m\n",
      "üöÄ HyperSloth Token Efficiency Report (Rank 0)\n",
      "+---------------------+----------------+-----------------------+\n",
      "| Stage               |   Total Tokens |   Token Utilization % |\n",
      "+=====================+================+=======================+\n",
      "| Before Optimization |      2,648,348 |                69.26% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "| After Optimization  |      1,834,304 |               100.00% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "\u001b[0m\n",
      "\u001b[32m03:08:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU1\u001b[0m | \u001b[36minner_training_loop.py:100\u001b[0m | \u001b[1m\n",
      "üöÄ HyperSloth Token Efficiency Report (Rank 1)\n",
      "+---------------------+----------------+-----------------------+\n",
      "| Stage               |   Total Tokens |   Token Utilization % |\n",
      "+=====================+================+=======================+\n",
      "| Before Optimization |      2,648,348 |                69.26% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "| After Optimization  |      1,834,304 |               100.00% |\n",
      "+---------------------+----------------+-----------------------+\n",
      "\u001b[0m\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/fastcore/parallel.py\", line 29, in g\n",
      "    res = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/HyperSloth/scripts/hp_trainer.py\", line 223, in run_in_process\n",
      "    train_on_single_gpu(*args, **kwargs)\n",
      "  File \"/home/anhvth5/projects/hypersloth/HyperSloth/scripts/hp_trainer.py\", line 77, in train_on_single_gpu\n",
      "    trainer.train()\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py\", line 2240, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 315, in _fast_inner_training_loop\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 846, in training_step\n",
      "    return super().training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 31, in _unsloth_training_step\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 835, in compute_loss\n",
      "    outputs = super().compute_loss(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mHyperSloth\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhp_trainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_multiprocess_training, setup_envs\n\u001b[32m      3\u001b[39m setup_envs(hyper_config_model, training_config_model)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_multiprocess_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyper_config_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_config_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_config_model\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/hypersloth/HyperSloth/scripts/hp_trainer.py:245\u001b[39m, in \u001b[36mrun_multiprocess_training\u001b[39m\u001b[34m(gpus, hyper_config, training_config)\u001b[39m\n\u001b[32m    243\u001b[39m                 processes.remove(proc)\n\u001b[32m    244\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m    246\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll processes finished\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/_utils.py\", line 1043, in _unsloth_pre_compute_loss\n",
      "    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py\", line 3810, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 818, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 806, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/peft/peft_model.py\", line 1757, in forward\n",
      "    return self.base_model(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/peft/tuners/tuners_utils.py\", line 193, in forward\n",
      "    return self.model.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/.cache/unsloth_compiled_cache_1/unsloth_compiled_module_qwen3.py\", line 588, in forward\n",
      "    return Qwen3ForCausalLM_forward(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
      "    output = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/.cache/unsloth_compiled_cache_1/unsloth_compiled_module_qwen3.py\", line 410, in Qwen3ForCausalLM_forward\n",
      "    outputs: BaseModelOutputWithPast = self.model(\n",
      "                                       ^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
      "    output = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 463, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/modeling_layers.py\", line 47, in __call__\n",
      "    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/_compile.py\", line 51, in inner\n",
      "    return disable_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/checkpoint.py\", line 488, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/autograd/function.py\", line 575, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/unsloth_zoo/gradient_checkpointing.py\", line 475, in forward\n",
      "    outputs = run_function(*args)\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 284, in forward\n",
      "    hidden_states, self_attn_weights = self.self_attn(\n",
      "                                       ^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/.cache/unsloth_compiled_cache_1/unsloth_compiled_module_qwen3.py\", line 323, in forward\n",
      "    return Qwen3Attention_forward(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/.cache/unsloth_compiled_cache_1/unsloth_compiled_module_qwen3.py\", line 242, in Qwen3Attention_forward\n",
      "    key_states = self.k_norm(self.k_proj(hidden_states).view(hidden_shape)).transpose(1, 2)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/.cache/unsloth_compiled_cache_1/Linear4bit_peft_forward.py\", line 55, in unsloth_forward\n",
      "    result = self.base_layer(x, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/bitsandbytes/nn/modules.py\", line 496, in forward\n",
      "    return bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state).to(inp_dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py\", line 393, in matmul_4bit\n",
      "    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/autograd/function.py\", line 575, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py\", line 305, in forward\n",
      "    @staticmethod\n",
      "    \n",
      "KeyboardInterrupt\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/fastcore/parallel.py\", line 29, in g\n",
      "    res = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anhvth5/projects/hypersloth/HyperSloth/scripts/hp_trainer.py\", line 223, in run_in_process\n",
      "    train_on_single_gpu(*args, **kwargs)\n",
      "  File \"/home/anhvth5/projects/hypersloth/HyperSloth/scripts/hp_trainer.py\", line 77, in train_on_single_gpu\n",
      "    trainer.train()\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py\", line 2240, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 315, in _fast_inner_training_loop\n",
      "  File \"/home/anhvth5/projects/hypersloth/notebooks/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 846, in training_step\n",
      "    return super().training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 77, in _unsloth_training_step\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/accelerator.py\", line 2473, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/_tensor.py\", line 648, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 353, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/anhvth5/miniconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "setup_envs(hyper_config_model, training_config_model)\n",
    "\n",
    "run_multiprocess_training(\n",
    "    hyper_config_model.training.gpus, hyper_config_model, training_config_model\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
